import os
import shutil
import lxml.etree as ET
from bs4 import BeautifulSoup
from markdownify import markdownify as md
from .base import BaseAdapter
from ..core.structures import DocNode
from ..converters.html_md import ContentConverter
from ..utils.path_utils import PathUtils  # <--- [æ–°å¢ž] å¯¼å…¥è·¯å¾„æ¸…æ´—å·¥å…·

class AbaqusAdapter(BaseAdapter):
    def __init__(self, source_root, out_root, logger_func):
        super().__init__(source_root, out_root, logger_func)
        self.master_toc = "DSSIMULIA_Established_TOC.xml"
        self.converter = ContentConverter()
        self.pdf_items = []

    def parse_structure(self) -> list[DocNode]:
        """è§£æžç»“æž„å¹¶å®¡è®¡ PDF (ä¿æŒé€»è¾‘ä¸å˜)"""
        master_path = os.path.join(self.src_root, self.master_toc)
        if not os.path.exists(master_path):
            self.log(f"âŒ æ‰¾ä¸åˆ° Abaqus ä¸»è¡¨æ–‡ä»¶: {master_path}")
            return []

        root_nodes = []
        self.pdf_items = []
        try:
            parser = ET.XMLParser(recover=True, encoding='utf-8')
            tree = ET.parse(master_path, parser=parser)
            
            # æ‰«æå¹¶é”å®šé¡¶å±‚ç¼–å·
            for i, item in enumerate(tree.xpath("/Root/ITEM"), start=1):
                module_name = item.get("name")
                module_node = DocNode(title=module_name, level=1, index=i, 
                                      source_path=self._get_abs_path("", item.get("href")), is_container=True)

                # æ‰«æå¹¶é”å®šä¹¦ç±ç¼–å· (é’ˆå¯¹ fe-safe)
                for j, sub_item in enumerate(item.xpath("./DITEM | ./ITEM"), start=1):
                    sub_name = sub_item.get("name")
                    sub_href = sub_item.get("href")
                    child_toc_rel = sub_item.get("childtoc")
                    
                    if sub_href and sub_href.lower().endswith(".pdf"):
                        self.pdf_items.append(sub_name)

                    sub_node = DocNode(title=sub_name, level=2, index=j, 
                                        source_path=self._get_abs_path("", sub_href), 
                                        is_container=True if child_toc_rel or sub_item.xpath("./ITEM") else False)
                    
                    if child_toc_rel:
                        self._parse_child_xml(os.path.join(self.src_root, child_toc_rel), sub_node, os.path.dirname(child_toc_rel), 3)
                    elif sub_item.xpath("./ITEM"):
                        self._walk_internal_items(sub_item, sub_node, 3)
                    module_node.add_child(sub_node)
                root_nodes.append(module_node)

            if self.pdf_items:
                self.log("\n--- ðŸ“„ PDF èµ„æºå®¡è®¡æŠ¥å‘Š ---")
                for pdf_name in self.pdf_items:
                    self.log(f"ðŸ’¡ æ¨¡å— [{pdf_name}] æŒ‡å‘ PDFï¼Œå°†æ‰§è¡Œç‰©ç†å¤åˆ¶ã€‚")
            self.log("âœ… Abaqus ç›®å½•æž¶æž„æ‰«æå®Œæˆã€‚")
        except Exception as e:
            self.log(f"âŒ è§£æžå‡ºé”™: {str(e)}")
        return root_nodes

    def read_file_content(self, node: DocNode, image_out_dir: str = None) -> str:
        if not node.source_path or not os.path.exists(node.source_path): return ""
        
        # === PDF å¤åˆ¶é€»è¾‘ (å·²ä¿®å¤ç‰¹æ®Šå­—ç¬¦æŠ¥é”™) ===
        if node.source_path.lower().endswith(".pdf"):
            try:
                # ç¡®å®šç›®æ ‡æ–‡ä»¶å¤¹ (output/Set/assets/..) çš„ä¸Šä¸€çº§
                dest_dir = os.path.dirname(image_out_dir)
                if not os.path.exists(dest_dir): os.makedirs(dest_dir)
                
                # [æ ¸å¿ƒä¿®å¤] ä½¿ç”¨ PathUtils æ¸…æ´—æ–‡ä»¶å (ä¾‹å¦‚ "What's New?" -> "What_s New_")
                safe_title = PathUtils.sanitize_filename(node.title)
                new_filename = f"{safe_title}-pdf.pdf"
                
                dest_path = os.path.join(dest_dir, new_filename)
                
                if not os.path.exists(dest_path):
                    shutil.copy2(node.source_path, dest_path)
                    
                return None # è¿”å›ž None è¡¨ç¤ºä¸ç”± Engine ç”Ÿæˆ .md æ–‡ä»¶
            except Exception as e:
                self.log(f"âš ï¸ PDF å¤åˆ¶å¤±è´¥ [{node.title}]: {e}")
                return ""

        # === Abaqus HTML è½¬æ¢é€»è¾‘ ===
        try:
            with open(node.source_path, 'r', encoding='utf-8', errors='ignore') as f:
                soup = BeautifulSoup(f.read(), 'html.parser')
            h1_tag = soup.find('h1')
            header_md = md(str(h1_tag), heading_style="ATX") + "\n\n" if h1_tag else ""
            content_area = soup.find('div', class_='conbody') or soup.find('div', class_='body') or soup.body
            if not content_area: return ""
            
            # æ¸…ç†å™ªéŸ³
            for junk in content_area.select('script, style, .navheader, .navfooter'): junk.decompose()
            
            # å›¾ç‰‡å¤„ç†
            self._process_abaqus_images(content_area, os.path.dirname(node.source_path), image_out_dir)

            main_md = md(str(content_area), heading_style="ATX", strip=['a'], newline_style="BACKSLASH")
            return header_md + main_md
        except Exception as e:
            return f"Conversion Error: {e}"

    def _process_abaqus_images(self, soup_element, src_dir, graphics_dir):
        """å¤ç”¨å›¾ç‰‡æ¬è¿ä¸Žå…¬å¼ä¿®å¤é€»è¾‘"""
        for img in soup_element.find_all(['img', 'svg']):
            alt = img.get('alt', '') or (img.title.string if img.title else '')
            if alt and any(c in alt for c in ['=', '\\', '+']):
                img.replace_with(f" ${alt}$ ")
                continue
            src = img.get('src')
            if src and not src.startswith(('http', 'data:')) and graphics_dir:
                abs_src = os.path.normpath(os.path.join(src_dir, src))
                if os.path.exists(abs_src):
                    if not os.path.exists(graphics_dir): os.makedirs(graphics_dir)
                    fname = os.path.basename(abs_src)
                    dst_path = os.path.join(graphics_dir, fname)
                    if not os.path.exists(dst_path):
                        try: shutil.copy2(abs_src, dst_path)
                        except: pass
                    img['src'] = f"assets/{fname}"

    def _parse_child_xml(self, xml_path, parent_node, context_dir, level):
        try:
            parser = ET.XMLParser(recover=True, encoding='utf-8')
            tree = ET.parse(xml_path, parser=parser)
            def _walk_item(element, current_p_node, current_level):
                for i, item in enumerate(element.xpath("./ITEM"), start=1):
                    title = item.get("title")
                    abs_html_path = self._get_abs_path(context_dir, item.get("href"))
                    child_node = DocNode(title=title, level=current_level, index=i, source_path=abs_html_path, 
                                         is_container=len(item.xpath("./ITEM")) > 0)
                    current_p_node.add_child(child_node)
                    if child_node.is_container: _walk_item(item, child_node, current_level + 1)
            _walk_item(tree.getroot(), parent_node, level)
        except: pass

    def _walk_internal_items(self, element, current_p_node, level):
        for i, item in enumerate(element.xpath("./ITEM"), start=1):
            title = item.get("name") or item.get("title")
            child_node = DocNode(title=title, level=level, index=i, source_path=self._get_abs_path("", item.get("href")), 
                                 is_container=True if item.xpath("./ITEM") else False)
            current_p_node.add_child(child_node)
            if child_node.is_container: self._walk_internal_items(item, child_node, level + 1)

    def _get_abs_path(self, context_dir, href):
        if not href: return None
        clean_href = href.split('#')[0]
        abs_path = os.path.normpath(os.path.join(self.src_root, context_dir, clean_href))
        return abs_path if os.path.exists(abs_path) else None

    def process_task(self, task): pass
